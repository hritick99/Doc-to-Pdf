# DOCX to PDF Conversion Service

A scalable microservice for bulk DOCX to PDF conversion with asynchronous processing.

## ğŸš€ Quick Start

### Prerequisites
- Docker Desktop installed
- 4GB RAM minimum

### Docker Configuration (Optional but Recommended)

Configure Docker to use registry mirrors for faster image downloads:

1. Open Docker Desktop
2. Go to Settings (gear icon)
3. Click on "Docker Engine"
4. Add this configuration:

```json
{
  "builder": {
    "gc": {
      "defaultKeepStorage": "20GB",
      "enabled": true
    }
  },
  "experimental": false,
  "registry-mirrors": [
    "https://mirror.gcr.io",
    "https://dockerhub.azk8s.cn",
    "https://registry.docker-cn.com"
  ]
}
```

5. Click "Apply & Restart"

### Setup & Run

```bash
# 1. Clone the repository
git clone <repository-url>
cd docx-to-pdf-service

# 2. Start all services
docker-compose up --build -d

# 3. Verify services are running
docker-compose ps
```

Expected output:
```
NAME                    STATUS              PORTS
doc-to-pdf-api-1       Up (healthy)        0.0.0.0:8000->8000/tcp
doc-to-pdf-db-1        Up (healthy)        0.0.0.0:5432->5432/tcp
doc-to-pdf-redis-1     Up (healthy)        0.0.0.0:6379->6379/tcp
doc-to-pdf-worker-1    Up
doc-to-pdf-worker-2    Up
doc-to-pdf-flower-1    Up                  0.0.0.0:5555->5555/tcp
```

### Access Points
- **API**: http://localhost:8000
- **API Documentation**: http://localhost:8000/docs
- **Task Monitoring**: http://localhost:5555

---

## ğŸ—ï¸ Architecture

### System Components

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Docker Environment                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚   FastAPI    â”‚   â”‚  PostgreSQL  â”‚   â”‚    Redis     â”‚   â”‚
â”‚  â”‚ API Server   â”‚â”€â”€â”€â”‚   Database   â”‚   â”‚    Queue     â”‚   â”‚
â”‚  â”‚ (Port 8000)  â”‚   â”‚ (Port 5432)  â”‚   â”‚ (Port 6379)  â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚         â”‚                                       â”‚           â”‚
â”‚         â”‚                                       â”‚           â”‚
â”‚         â–¼                                       â–¼           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚      Celery Workers (2 replicas, 2 tasks each)       â”‚  â”‚
â”‚  â”‚         Processing DOCX â†’ PDF conversions            â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚         â”‚                                                   â”‚
â”‚         â–¼                                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚    Flower    â”‚         â”‚  Shared Docker Volume    â”‚    â”‚
â”‚  â”‚ (Port 5555)  â”‚         â”‚  /app/storage/           â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚  - temp/  (uploads)      â”‚    â”‚
â”‚                            â”‚  - output/ (PDFs)        â”‚    â”‚
â”‚                            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Workflow Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Client  â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
     â”‚
     â”‚ 1. Upload ZIP with DOCX files
     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   FastAPI API   â”‚
â”‚  POST /jobs     â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚
     â”‚ 2. Extract files & Save to /temp
     â”‚ 3. Create job in PostgreSQL
     â”‚ 4. Enqueue tasks to Redis
     â”‚ 5. Return job_id immediately
     â”‚
     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Redis Queue    â”‚
â”‚  [Task][Task]   â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚
     â”‚ 6. Workers pull tasks
     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Celery Workers (Parallel)          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚Worker 1 â”‚  â”‚Worker 2 â”‚          â”‚
â”‚  â”‚Task 1   â”‚  â”‚Task 2   â”‚          â”‚
â”‚  â”‚Task 3   â”‚  â”‚Task 4   â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚
     â”‚ 7. Read DOCX from /temp
     â”‚ 8. Convert to PDF (python-docx + reportlab)
     â”‚ 9. Save PDF to /output
     â”‚ 10. Update file status in PostgreSQL
     â”‚
     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  All files done â”‚
â”‚  Trigger finale â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚
     â”‚ 11. Create result ZIP
     â”‚ 12. Update job status to COMPLETED
     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   PostgreSQL    â”‚
â”‚ Job: COMPLETED  â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚
     â”‚ 13. Client polls GET /jobs/{id}
     â”‚ 14. Status: COMPLETED + download_url
     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Client  â”‚ 15. Download ZIP with PDFs
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Data Flow

```
Upload â†’ Extract â†’ Queue â†’ Process â†’ Archive â†’ Download
  â†“        â†“        â†“        â†“         â†“         â†“
 ZIP     DOCX    Redis   Workers    ZIP      Client
         files   Tasks   Convert    File
                         to PDF
```

---

## ğŸ§ª Testing

### Run Automated Tests

```bash
# Install test dependencies
pip install requests python-docx

# Run the test
python tests/test_integration.py
```

Expected output:
```
============================================================
Testing DOCX to PDF Conversion Service
============================================================

1. Creating test documents and uploading...
   âœ“ Job created: a1b2c3d4-...
   âœ“ File count: 3

2. Waiting for conversion to complete...
   âœ“ Conversion completed!

3. Checking individual file statuses:
   âœ“ document_1.docx: COMPLETED
   âœ“ document_2.docx: COMPLETED
   âœ“ document_3.docx: COMPLETED

4. Downloading results...
   âœ“ Downloaded: test_output_a1b2c3d4-....zip
   âœ“ Size: 15234 bytes

5. Verifying zip contents:
   âœ“ document_1.pdf (4567 bytes)
   âœ“ document_2.pdf (4823 bytes)
   âœ“ document_3.pdf (4691 bytes)

============================================================
All tests passed! âœ“
============================================================
```

### Manual Testing

**Using Swagger UI (Easiest):**

1. Open http://localhost:8000/docs
2. Find `POST /api/v1/jobs` â†’ Click "Try it out"
3. Upload a ZIP file with DOCX files â†’ Click "Execute"
4. Copy the `job_id` from response
5. Find `GET /api/v1/jobs/{job_id}` â†’ Paste job_id â†’ Click "Execute"
6. Wait until status is "COMPLETED"
7. Find `GET /api/v1/jobs/{job_id}/download` â†’ Click "Execute" â†’ Download file

**Using cURL:**

```bash
# 1. Upload documents
curl -X POST http://localhost:8000/api/v1/jobs \
  -F "file=@documents.zip"

# Response: {"job_id":"a1b2c3d4-...","file_count":5}

# 2. Check status (replace {job_id})
curl http://localhost:8000/api/v1/jobs/{job_id}

# 3. Download results when status is COMPLETED
curl -O http://localhost:8000/api/v1/jobs/{job_id}/download
```

---

## ğŸ“š API Endpoints

### 1. Submit Job
**POST** `/api/v1/jobs`
- Upload ZIP file with DOCX files
- Returns: `job_id` and `file_count`

### 2. Check Status
**GET** `/api/v1/jobs/{job_id}`
- Returns: job status and individual file statuses
- Status values: PENDING, IN_PROGRESS, COMPLETED, FAILED

### 3. Download Results
**GET** `/api/v1/jobs/{job_id}/download`
- Returns: ZIP file with converted PDFs
- Only available when status is COMPLETED

### 4. Health Check
**GET** `/health`
- Returns: Service health status

---

## ğŸ› ï¸ Common Commands

```bash
# View logs
docker-compose logs -f

# View specific service logs
docker-compose logs -f worker

# Restart services
docker-compose restart

# Stop services
docker-compose down

# Stop and remove all data
docker-compose down -v

# Scale workers
docker-compose up --scale worker=5 -d
```

---

## ğŸ› Troubleshooting

**Services won't start:**
```bash
docker-compose down -v
docker system prune -f
docker-compose up --build -d
```

**Port already in use:**
```bash
# Change port in docker-compose.yml
ports:
  - "8001:8000"  # Use 8001 instead of 8000
```

**Download not working:**
```bash
# Check job status first
curl http://localhost:8000/api/v1/jobs/{job_id}

# Status must be "COMPLETED"
```

---

## ğŸ—„ï¸ Database Inspection

### View Database Tables

```powershell
# Connect to PostgreSQL
docker-compose exec db psql -U postgres -d docx_converter
```

Inside psql, run these commands:

```sql
-- List all tables
\dt

-- View table structure
\d jobs
\d files

-- View all jobs
SELECT * FROM jobs ORDER BY created_at DESC;

-- View all files
SELECT * FROM files;

-- Count records
SELECT COUNT(*) FROM jobs;
SELECT COUNT(*) FROM files;

-- Jobs by status
SELECT status, COUNT(*) FROM jobs GROUP BY status;

-- Files by status
SELECT status, COUNT(*) FROM files GROUP BY status;

-- View specific job files (replace job_id)
SELECT filename, status, error_message 
FROM files 
WHERE job_id = 'your-job-id-here';

-- Exit psql
\q
```

### Quick Database Queries

```powershell
# List tables (one-line)
docker-compose exec db psql -U postgres -d docx_converter -c "\dt"

# Count jobs
docker-compose exec db psql -U postgres -d docx_converter -c "SELECT COUNT(*) FROM jobs;"

# View latest job
docker-compose exec db psql -U postgres -d docx_converter -c "SELECT * FROM jobs ORDER BY created_at DESC LIMIT 1;"
```

---

## ğŸ“ Project Structure

```
docx-to-pdf-service/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py              # FastAPI application
â”‚   â”œâ”€â”€ tasks.py             # Celery conversion tasks
â”‚   â”œâ”€â”€ models.py            # Database models
â”‚   â”œâ”€â”€ database.py          # Database connection
â”‚   â””â”€â”€ utils.py             # Helper functions
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test_integration.py  # Integration tests
â”œâ”€â”€ .env                     # Environment variables
â”œâ”€â”€ docker-compose.yml       # Service configuration
â”œâ”€â”€ Dockerfile               # Container image
â”œâ”€â”€ requirements.txt         # Python dependencies
â””â”€â”€ README.md               # This file
```

---

## ğŸ“‹ Requirements Met

âœ… Bulk file upload via ZIP  
âœ… Asynchronous processing with Celery  
âœ… RESTful API with FastAPI  
âœ… Job status tracking  
âœ… Individual file status tracking  
âœ… Error handling (partial failures)  
âœ… Result download as ZIP  
âœ… Docker containerization  
âœ… Single command deployment  
âœ… Scalable architecture  

---

## ğŸ”— Technology Stack

- Python 3.11
- FastAPI 0.104
- Celery 5.3
- PostgreSQL 15
- Redis 7
- Docker & Docker Compose

---

**Built for Backend Developer Technical Assignment**